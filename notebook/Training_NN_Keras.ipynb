{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of a Neural Network with Keras\n",
    "\n",
    "### Level: Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how to use Keras library to create a basic pipeline for ANN training. \n",
    "\n",
    "First, we create a basic neural network. Then, we adress the pipeline for training it. Finally, we save and use this model to make some predictions.\n",
    "\n",
    "At the end of this notebook there is some useful documentation of this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install dependencies\n",
    "\n",
    "First, we have to install from terminal the libraries we are going to use:\n",
    "\n",
    "- pip install pandas\n",
    "- pip install scikit-learn\n",
    "- pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIP**\n",
    "\n",
    "For a cleaner version, we create what is called an `environment`, which we will use to install all needed packages [2].\n",
    "\n",
    "In `VSCode`, just go to `Terminal`>`New Terminal` and:\n",
    "\n",
    "- Install conda, changing the second line with the version for your OS [1].\n",
    "```\n",
    "mkdir -p ~/miniconda3\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n",
    "bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n",
    "rm -rf ~/miniconda3/miniconda.sh\n",
    "```\n",
    "- Create and activate your environment.\n",
    "```\n",
    "conda create -n NN_training\n",
    "conda activate NN_training\n",
    "```\n",
    "\n",
    "- Install your libraries as previously indicated.\n",
    "\n",
    "- Activate the environment in your notebook, if needed. In VSCode, click on `Select Kernel`>`Python Environments...`>`NN_training`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies\n",
    "\n",
    "Once installed, we import in our program the necessary functions of those dependencies to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 19:05:59.123854: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 19:05:59.125519: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-20 19:05:59.133583: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-20 19:05:59.151116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732125959.189462   67038 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732125959.198541   67038 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 19:05:59.228683: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 19:06:02.048210: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# model optimizer\n",
    "loss = keras.losses.MeanAbsoluteError()  # or \"mae\"\n",
    "lr = 1e-3\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=lr)  # or \"nadam\"\n",
    "metrics = [\"accuracy\", \"mse\"]\n",
    "\n",
    "# training\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "# early stopping\n",
    "monitor = \"val_loss\"\n",
    "patience = int(0.1 * epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "\n",
    "This will be different for each proyect. Once you have enough and valuable data (which we all know is a difficult task!), it has to be loaded and processed depending of their format, even normalizing/standardizing it, which is a highly recommended practice [7]. \n",
    "\n",
    "A personal recomendation is to use `pandas` for this task, as indicated in commented lines.\n",
    "\n",
    "For didactic purposes, we define a set of data with binary representation of 0 to 3 as input and the decimal representation as output.\n",
    "\n",
    "Once we have meaningful and clean data, we split it into `train`/`test` splits, being the first the data used for training our Neural Network and the last to evaluate its performance [3]. \n",
    "\n",
    "A common split is 90/10, so we use it as starting point [9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our clean and nice normalized data is saved in features/targets parquets\n",
    "# X = pd.read_parquet(\"features.parquet\")\n",
    "# y = pd.read_parquet(\"targets.parquet\")\n",
    "\n",
    "# synthetic data of example\n",
    "X = pd.DataFrame(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 0],\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "        [1, 1],\n",
    "        [1, 0],\n",
    "        [1, 1],\n",
    "        [0, 0],\n",
    "        [0, 0],\n",
    "    ]\n",
    ")\n",
    "y = pd.Series([0, 1, 2, 2, 1, 1, 3, 2, 3, 0, 0])\n",
    "\n",
    "# we set a fixed random state for reproducibility and teaching purposes,\n",
    "# but our results have to be consistent across multiple seeds to be relevant\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.9, test_size=0.1, random_state=0\n",
    ")\n",
    "\n",
    "# also fix keras random seed\n",
    "keras.utils.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network definition\n",
    "\n",
    "Although we can define Multi-layer Perceptrons with scikit-learn library [4], we adress the use of Keras for higher flexibility.\n",
    "\n",
    "With Keras, we can set the model layers several ways, here we adress what they call the `Functional API` [5, 6].\n",
    "\n",
    "In addition, we define the optimizer, this is, the method to find the attributes of the neural network that reduces the loss, i.e., the difference between the target and predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"NN_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"NN_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,817</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,817\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# shape of input features and output predictions (do not worry for this! could be defined just by hand)\n",
    "features_shape = X_train.iloc[0].shape\n",
    "target_shape = y_train.iloc[0].shape if bool(y_train.iloc[0].shape) else 1\n",
    "\n",
    "# input layer, which receives X_train\n",
    "input_layer = keras.Input(shape=features_shape)\n",
    "# inner layers, with SELU activation function as recommended in [7]\n",
    "inner_layer_1 = keras.layers.Dense(64, activation=\"selu\")(input_layer)\n",
    "inner_layer_2 = keras.layers.Dense(32, activation=\"selu\")(inner_layer_1)\n",
    "inner_layer_3 = keras.layers.Dense(16, activation=\"selu\")(inner_layer_2)\n",
    "# output layer, no activation as we are not simulating, e.g., a classification\n",
    "# problem. Notice in this and other cases an activation function in the output\n",
    "# layer is required\n",
    "output_layer = keras.layers.Dense(target_shape)(inner_layer_3)\n",
    "\n",
    "# determined the layers, create the model\n",
    "model = keras.Model(inputs=input_layer, outputs=output_layer, name=\"NN_model\")\n",
    "\n",
    "# specify optimizer parameters, again with recomendations in [7]\n",
    "model.compile(\n",
    "    loss=loss,  # function to evaluate the difference between target and predicted values\n",
    "    optimizer=optimizer,  # optimization method\n",
    "    metrics=metrics,  # additional metrics to track\n",
    ")\n",
    "\n",
    "# see our created model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, some regularization techniques like dropout layers can be added, but we skip it for future lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiperparameter optimization and training\n",
    "\n",
    "Once we have our model, we train it with the use of an early stopping with a `train`/`validation` split of 90/10 [9], until `val_loss` increases. \n",
    "\n",
    "Finally, evaluate and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3750 - loss: 0.9731 - mse: 1.4732 - val_accuracy: 1.0000 - val_loss: 0.2090 - val_mse: 0.0437\n",
      "Epoch 2/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3750 - loss: 0.8486 - mse: 1.0655 - val_accuracy: 1.0000 - val_loss: 0.2163 - val_mse: 0.0468\n",
      "Epoch 3/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.3750 - loss: 0.7517 - mse: 0.8315 - val_accuracy: 1.0000 - val_loss: 0.2456 - val_mse: 0.0603\n",
      "Epoch 4/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.3750 - loss: 0.6627 - mse: 0.6314 - val_accuracy: 1.0000 - val_loss: 0.2735 - val_mse: 0.0748\n",
      "Epoch 5/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3750 - loss: 0.5739 - mse: 0.4600 - val_accuracy: 1.0000 - val_loss: 0.3041 - val_mse: 0.0924\n",
      "Epoch 6/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3750 - loss: 0.4835 - mse: 0.3151 - val_accuracy: 1.0000 - val_loss: 0.3358 - val_mse: 0.1128\n",
      "Epoch 7/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3750 - loss: 0.3909 - mse: 0.1981 - val_accuracy: 1.0000 - val_loss: 0.3789 - val_mse: 0.1436\n",
      "Epoch 8/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3750 - loss: 0.2748 - mse: 0.0959 - val_accuracy: 1.0000 - val_loss: 0.4270 - val_mse: 0.1823\n",
      "Epoch 9/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3750 - loss: 0.1520 - mse: 0.0430 - val_accuracy: 1.0000 - val_loss: 0.4186 - val_mse: 0.1753\n",
      "Epoch 10/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3750 - loss: 0.1238 - mse: 0.0344 - val_accuracy: 1.0000 - val_loss: 0.4568 - val_mse: 0.2087\n",
      "Epoch 11/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3750 - loss: 0.1531 - mse: 0.0424 - val_accuracy: 1.0000 - val_loss: 0.4518 - val_mse: 0.2042\n",
      "Epoch 12/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.3750 - loss: 0.1491 - mse: 0.0409 - val_accuracy: 1.0000 - val_loss: 0.3210 - val_mse: 0.1031\n",
      "Epoch 13/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.3750 - loss: 0.1066 - mse: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.3248 - val_mse: 0.1055\n",
      "Epoch 14/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.3750 - loss: 0.1012 - mse: 0.0183 - val_accuracy: 1.0000 - val_loss: 0.3302 - val_mse: 0.1090\n",
      "Epoch 15/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.3750 - loss: 0.0945 - mse: 0.0173 - val_accuracy: 1.0000 - val_loss: 0.3384 - val_mse: 0.1145\n",
      "Epoch 16/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3750 - loss: 0.0863 - mse: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.3481 - val_mse: 0.1212\n",
      "Epoch 17/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3750 - loss: 0.0763 - mse: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.3603 - val_mse: 0.1298\n",
      "Epoch 18/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.3750 - loss: 0.0698 - mse: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.3982 - val_mse: 0.1586\n",
      "Epoch 19/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3750 - loss: 0.1336 - mse: 0.0298 - val_accuracy: 1.0000 - val_loss: 0.3033 - val_mse: 0.0920\n",
      "Epoch 20/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3750 - loss: 0.0668 - mse: 0.0125 - val_accuracy: 1.0000 - val_loss: 0.3028 - val_mse: 0.0917\n",
      "Epoch 21/200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.3750 - loss: 0.0612 - mse: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.3245 - val_mse: 0.1053\n",
      "\n",
      "[test loss, test accuracy, test mse]: [0.17176593840122223, 1.0, 0.05282317101955414]\n"
     ]
    }
   ],
   "source": [
    "# set an early stopping for training\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor=monitor, patience=patience)]\n",
    "\n",
    "# train the model while monitoring it\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"\\n[test loss, test accuracy, test mse]:\", score)\n",
    "\n",
    "# save the final model\n",
    "model.save(\"../models/model__Training_NN_Keras.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use your model!\n",
    "\n",
    "Load saved model and use it for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\n",
      "Sample [0 1] \n",
      "Prediction [1.3244736] \n",
      "True 1\n",
      "\n",
      "\n",
      "Sample [0 0] \n",
      "Prediction [-0.01905827] \n",
      "True 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load saved model\n",
    "model = keras.saving.load_model(\"../models/model__Training_NN_Keras.keras\")\n",
    "\n",
    "# make some predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# print test data, predicted value and true value\n",
    "for idx, test_idx in enumerate(X_test.index):\n",
    "    sample = X_test.loc[test_idx].values\n",
    "    prediction = predictions[idx]\n",
    "    true = y_test[test_idx]\n",
    "    print(f\"\\nSample {sample} \\nPrediction {prediction} \\nTrue {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References \n",
    ".. [1] https://docs.anaconda.com/miniconda/ \n",
    "\n",
    ".. [2] https://code.visualstudio.com/docs/python/environments#_work-with-python-interpreters \n",
    "\n",
    ".. [3] https://scikit-learn.org/1.5/modules/cross_validation.html#cross-validation \n",
    "\n",
    ".. [4] https://scikit-learn.org/1.5/modules/neural_networks_supervised.html\n",
    "\n",
    ".. [5] https://keras.io/getting_started/intro_to_keras_for_engineers/ \n",
    "\n",
    ".. [6] https://keras.io/guides/functional_api/\n",
    "\n",
    ".. [7] A. Géron. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow. O’Reilly Media, 2019.\n",
    "\n",
    ".. [8] https://keras.io/about/  \n",
    "\n",
    ".. [9] J.J. García-Esteban. Deep Learning and Radiative Heat Transfer. Universidad Autónoma de Madrid, 2024."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
